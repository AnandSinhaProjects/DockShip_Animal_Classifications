{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DOckship.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandSinhaProjects/DockShip_Animal_Classifications/blob/main/DOckship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKOhNqBH7JvS",
        "outputId": "8aa66ef8-2e55-485b-f630-b4fee046e302"
      },
      "source": [
        "!wget -O \"animal_breed_classification_ai_challenge-dataset.zip\" \"https://dockship-job-models.s3.ap-south-1.amazonaws.com/6707c47a761bdd2f3c52480c3fd3a6fa?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210619%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210619T073423Z&X-Amz-Expires=1800&X-Amz-Signature=be7d1fbd01ae8a659914cedfca9904b59503c7fa45a18e44811b9c97492c14be&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22animal_breed_classification_ai_challenge-dataset.zip%22\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-19 07:35:06--  https://dockship-job-models.s3.ap-south-1.amazonaws.com/6707c47a761bdd2f3c52480c3fd3a6fa?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210619%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210619T073423Z&X-Amz-Expires=1800&X-Amz-Signature=be7d1fbd01ae8a659914cedfca9904b59503c7fa45a18e44811b9c97492c14be&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22animal_breed_classification_ai_challenge-dataset.zip%22\n",
            "Resolving dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)... 52.219.62.15\n",
            "Connecting to dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)|52.219.62.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788805172 (752M) [binary/octet-stream]\n",
            "Saving to: ‘animal_breed_classification_ai_challenge-dataset.zip’\n",
            "\n",
            "animal_breed_classi 100%[===================>] 752.26M  12.3MB/s    in 65s     \n",
            "\n",
            "2021-06-19 07:36:12 (11.6 MB/s) - ‘animal_breed_classification_ai_challenge-dataset.zip’ saved [788805172/788805172]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_xpExw7gRT"
      },
      "source": [
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,losses\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGLOuMQ68I7r"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = '/content/animal_breed_classification_ai_challenge-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPR7tix8PuU"
      },
      "source": [
        "from pathlib import Path \n",
        "# Path to validation directory\n",
        "test_data_dir = Path(\"/content/TEST\")\n",
        "\n",
        "# Path to test directory\n",
        "train_data_dir = Path(\"/content/TRAIN\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWftShY6-Sui",
        "outputId": "261b8e36-ba7c-4f58-d144-b1ff7fdafd4e"
      },
      "source": [
        "list(train_data_dir.glob('*'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/TRAIN/siamese'),\n",
              " PosixPath('/content/TRAIN/russian_blue'),\n",
              " PosixPath('/content/TRAIN/german_shorthaired'),\n",
              " PosixPath('/content/TRAIN/bengal'),\n",
              " PosixPath('/content/TRAIN/havanese'),\n",
              " PosixPath('/content/TRAIN/yorkshire_terrier'),\n",
              " PosixPath('/content/TRAIN/bombay'),\n",
              " PosixPath('/content/TRAIN/ragdoll'),\n",
              " PosixPath('/content/TRAIN/abyssinian'),\n",
              " PosixPath('/content/TRAIN/great_pyrenees'),\n",
              " PosixPath('/content/TRAIN/leonberger'),\n",
              " PosixPath('/content/TRAIN/british_shorthair'),\n",
              " PosixPath('/content/TRAIN/pug'),\n",
              " PosixPath('/content/TRAIN/saint_bernard'),\n",
              " PosixPath('/content/TRAIN/american_pit_bull_terrier'),\n",
              " PosixPath('/content/TRAIN/scottish_terrier'),\n",
              " PosixPath('/content/TRAIN/maine_coon'),\n",
              " PosixPath('/content/TRAIN/staffordshire_bull_terrier'),\n",
              " PosixPath('/content/TRAIN/shiba_inu'),\n",
              " PosixPath('/content/TRAIN/english_setter'),\n",
              " PosixPath('/content/TRAIN/newfoundland'),\n",
              " PosixPath('/content/TRAIN/english_cocker_spaniel'),\n",
              " PosixPath('/content/TRAIN/pomeranian'),\n",
              " PosixPath('/content/TRAIN/beagle'),\n",
              " PosixPath('/content/TRAIN/birman'),\n",
              " PosixPath('/content/TRAIN/basset_hound'),\n",
              " PosixPath('/content/TRAIN/wheaten_terrier'),\n",
              " PosixPath('/content/TRAIN/keeshond'),\n",
              " PosixPath('/content/TRAIN/miniature_pinscher'),\n",
              " PosixPath('/content/TRAIN/american_bulldog'),\n",
              " PosixPath('/content/TRAIN/persian'),\n",
              " PosixPath('/content/TRAIN/egyptian_mau'),\n",
              " PosixPath('/content/TRAIN/japanese_chin'),\n",
              " PosixPath('/content/TRAIN/sphynx'),\n",
              " PosixPath('/content/TRAIN/boxer'),\n",
              " PosixPath('/content/TRAIN/samoyed'),\n",
              " PosixPath('/content/TRAIN/chihuahua')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXuodTG1-XKR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "27770854-6142-46ba-958f-c4bb69b4043a"
      },
      "source": [
        "'''train_images_dict = {\n",
        "    'siamese': list(train_data_dir.glob('siamese/*')) ,   \n",
        "    'russian_blue': list(train_data_dir.glob('russian_blue/*')),\n",
        "    'german_shorthaired': list(train_data_dir.glob('german_shorthaired/*')),\n",
        "    'bengal': list(train_data_dir .glob('bengal/*')),\n",
        "    'havanese': list(train_data_dir.glob('havanese/*')),\n",
        "    'bombay': list(train_data_dir.glob('bombay/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "    'yorkshire_terrier': list(train_data_dir.glob('yorkshire_terrier/*')), \n",
        "}\n",
        "\n",
        "\n",
        "labels_dict = {\n",
        "     'building': \"building\", \n",
        "    'forest': \"forest\",\n",
        "    'glacier': \"glacier\",\n",
        "    'mountain': \"mountain\",\n",
        "    'sea': \"sea\",\n",
        "    'street': \"street\", \n",
        "}'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train_images_dict = {\\n    \\'siamese\\': list(train_data_dir.glob(\\'siamese/*\\')) ,   \\n    \\'russian_blue\\': list(train_data_dir.glob(\\'russian_blue/*\\')),\\n    \\'german_shorthaired\\': list(train_data_dir.glob(\\'german_shorthaired/*\\')),\\n    \\'bengal\\': list(train_data_dir .glob(\\'bengal/*\\')),\\n    \\'havanese\\': list(train_data_dir.glob(\\'havanese/*\\')),\\n    \\'bombay\\': list(train_data_dir.glob(\\'bombay/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n    \\'yorkshire_terrier\\': list(train_data_dir.glob(\\'yorkshire_terrier/*\\')), \\n}\\n\\n\\nlabels_dict = {\\n     \\'building\\': \"building\", \\n    \\'forest\\': \"forest\",\\n    \\'glacier\\': \"glacier\",\\n    \\'mountain\\': \"mountain\",\\n    \\'sea\\': \"sea\",\\n    \\'street\\': \"street\", \\n}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0HH3GOBA18S",
        "outputId": "1fb56af9-dc85-441e-8fc4-f01a5da14485"
      },
      "source": [
        "train_dir = '/content/TRAIN'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1./255,\n",
        "                             zoom_range = 0.2,\n",
        "                             width_shift_range = 0.2,\n",
        "                             height_shift_range = 0.2,\n",
        "                             rotation_range = 30,\n",
        "                             horizontal_flip=True,\n",
        "                             brightness_range=[0.8, 1.2],\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "X_train = datagen.flow_from_directory(\n",
        "    directory = train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 16,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5890 images belonging to 37 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS4-A7bqBBdr",
        "outputId": "f0ca9a66-1b96-4172-ddea-42559fe9e90a"
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "cnn_base = InceptionV3(include_top = False,\n",
        "                 weights = 'imagenet',\n",
        "                 input_shape = (150, 150, 3),\n",
        "                 pooling=max ,\n",
        "                 classes = 37,\n",
        "                 classifier_activation = 'softmax')\n",
        "\n",
        "cnn_base.trainable = False"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjcnd1DxBLvG"
      },
      "source": [
        "\n",
        "pretrainedCNN_model = Sequential([\n",
        "                                     cnn_base,\n",
        "                                  layers.Flatten(),\n",
        "                                  #layers.Dropout(0.25),\n",
        "                                  layers.Dense(640, activation = 'relu'),\n",
        "                                  layers.Dropout(0.25),\n",
        "                                  layers.Dense(328, activation = 'relu'),\n",
        "                                  #layers.Dropout(0.5),\n",
        "                                  #layers.Dense(128, activation = 'relu'),\n",
        "                                  layers.Dense(37, activation = 'softmax')  ,  \n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GOlssVeBRGD"
      },
      "source": [
        "pretrainedCNN_model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                            optimizer = keras.optimizers.Adam(0.0001),\n",
        "                            metrics = ['acc'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMAS9uQvCWbO"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/temp/checkpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtbtSmC2Cau3",
        "outputId": "b4d96bcb-7662-41d6-8771-e3e89a91e8a8"
      },
      "source": [
        "History = pretrainedCNN_model.fit(X_train, epochs=10,verbose=1,\n",
        "                                  callbacks=[model_checkpoint_callback])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "369/369 [==============================] - 91s 155ms/step - loss: 1.9732 - acc: 0.4925\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/10\n",
            "369/369 [==============================] - 57s 154ms/step - loss: 1.3311 - acc: 0.6165\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/10\n",
            "369/369 [==============================] - 58s 156ms/step - loss: 1.2097 - acc: 0.6465\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/10\n",
            "369/369 [==============================] - 58s 156ms/step - loss: 1.1184 - acc: 0.6698\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/10\n",
            "369/369 [==============================] - 58s 157ms/step - loss: 1.0828 - acc: 0.6817\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/10\n",
            "369/369 [==============================] - 58s 157ms/step - loss: 1.0247 - acc: 0.6966\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/10\n",
            "369/369 [==============================] - 58s 156ms/step - loss: 1.0113 - acc: 0.6986\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/10\n",
            "369/369 [==============================] - 58s 157ms/step - loss: 0.9746 - acc: 0.7049\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/10\n",
            "369/369 [==============================] - 58s 157ms/step - loss: 0.9711 - acc: 0.7075\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/10\n",
            "369/369 [==============================] - 58s 157ms/step - loss: 0.9776 - acc: 0.7022\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}