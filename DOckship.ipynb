{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DOckship.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandSinhaProjects/DockShip_Animal_Classifications/blob/main/DOckship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKOhNqBH7JvS",
        "outputId": "6dbca376-05b2-49c8-ae37-4e87b873dd93"
      },
      "source": [
        "!wget -O \"animal_breed_classification_ai_challenge-dataset.zip\" \"https://dockship-job-models.s3.ap-south-1.amazonaws.com/6707c47a761bdd2f3c52480c3fd3a6fa?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210619%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210619T162100Z&X-Amz-Expires=1800&X-Amz-Signature=aa42184094390ce827f2ea40ceea476c3abf881aca3f00d7c233c9d84e82e2e6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22animal_breed_classification_ai_challenge-dataset.zip%22\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-19 16:21:26--  https://dockship-job-models.s3.ap-south-1.amazonaws.com/6707c47a761bdd2f3c52480c3fd3a6fa?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210619%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210619T162100Z&X-Amz-Expires=1800&X-Amz-Signature=aa42184094390ce827f2ea40ceea476c3abf881aca3f00d7c233c9d84e82e2e6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22animal_breed_classification_ai_challenge-dataset.zip%22\n",
            "Resolving dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)... 52.219.64.42\n",
            "Connecting to dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)|52.219.64.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788805172 (752M) [binary/octet-stream]\n",
            "Saving to: ‘animal_breed_classification_ai_challenge-dataset.zip’\n",
            "\n",
            "animal_breed_classi 100%[===================>] 752.26M  12.7MB/s    in 62s     \n",
            "\n",
            "2021-06-19 16:22:29 (12.1 MB/s) - ‘animal_breed_classification_ai_challenge-dataset.zip’ saved [788805172/788805172]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_xpExw7gRT"
      },
      "source": [
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,losses\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGLOuMQ68I7r"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = '/content/animal_breed_classification_ai_challenge-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPR7tix8PuU"
      },
      "source": [
        "from pathlib import Path \n",
        "# Path to validation directory\n",
        "test_data_dir = Path(\"/content/TEST\")\n",
        "\n",
        "# Path to test directory\n",
        "train_data_dir = Path(\"/content/TRAIN\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWftShY6-Sui",
        "outputId": "851fc36b-b93c-4e77-b444-4164156327c8"
      },
      "source": [
        "list(train_data_dir.glob('*'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/TRAIN/siamese'),\n",
              " PosixPath('/content/TRAIN/russian_blue'),\n",
              " PosixPath('/content/TRAIN/german_shorthaired'),\n",
              " PosixPath('/content/TRAIN/bengal'),\n",
              " PosixPath('/content/TRAIN/havanese'),\n",
              " PosixPath('/content/TRAIN/yorkshire_terrier'),\n",
              " PosixPath('/content/TRAIN/bombay'),\n",
              " PosixPath('/content/TRAIN/ragdoll'),\n",
              " PosixPath('/content/TRAIN/abyssinian'),\n",
              " PosixPath('/content/TRAIN/great_pyrenees'),\n",
              " PosixPath('/content/TRAIN/leonberger'),\n",
              " PosixPath('/content/TRAIN/british_shorthair'),\n",
              " PosixPath('/content/TRAIN/pug'),\n",
              " PosixPath('/content/TRAIN/saint_bernard'),\n",
              " PosixPath('/content/TRAIN/american_pit_bull_terrier'),\n",
              " PosixPath('/content/TRAIN/scottish_terrier'),\n",
              " PosixPath('/content/TRAIN/maine_coon'),\n",
              " PosixPath('/content/TRAIN/staffordshire_bull_terrier'),\n",
              " PosixPath('/content/TRAIN/shiba_inu'),\n",
              " PosixPath('/content/TRAIN/english_setter'),\n",
              " PosixPath('/content/TRAIN/newfoundland'),\n",
              " PosixPath('/content/TRAIN/english_cocker_spaniel'),\n",
              " PosixPath('/content/TRAIN/pomeranian'),\n",
              " PosixPath('/content/TRAIN/beagle'),\n",
              " PosixPath('/content/TRAIN/birman'),\n",
              " PosixPath('/content/TRAIN/basset_hound'),\n",
              " PosixPath('/content/TRAIN/wheaten_terrier'),\n",
              " PosixPath('/content/TRAIN/keeshond'),\n",
              " PosixPath('/content/TRAIN/miniature_pinscher'),\n",
              " PosixPath('/content/TRAIN/american_bulldog'),\n",
              " PosixPath('/content/TRAIN/persian'),\n",
              " PosixPath('/content/TRAIN/egyptian_mau'),\n",
              " PosixPath('/content/TRAIN/japanese_chin'),\n",
              " PosixPath('/content/TRAIN/sphynx'),\n",
              " PosixPath('/content/TRAIN/boxer'),\n",
              " PosixPath('/content/TRAIN/samoyed'),\n",
              " PosixPath('/content/TRAIN/chihuahua')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0HH3GOBA18S",
        "outputId": "8b147201-c4c6-4244-ec39-e449bb86bd76"
      },
      "source": [
        "train_dir = '/content/TRAIN'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1./255,\n",
        "                             zoom_range = 0.2,\n",
        "                             width_shift_range = 0.2,\n",
        "                             height_shift_range = 0.2,\n",
        "                             rotation_range = 30,\n",
        "                             horizontal_flip=True,\n",
        "                             brightness_range=[0.8, 1.2],\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "X_train = datagen.flow_from_directory(\n",
        "    directory = train_dir,\n",
        "    target_size = (300, 300),\n",
        "    class_mode = \"categorical\"\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5890 images belonging to 37 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS4-A7bqBBdr",
        "outputId": "7f841fe4-7d73-47d4-c275-5a53887eb7ba"
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "cnn_base = InceptionV3(include_top = False,\n",
        "                 weights = 'imagenet',\n",
        "                 input_shape = (300, 300, 3),\n",
        "                 pooling=max ,\n",
        "                 classes = 37,\n",
        "                 classifier_activation = 'softmax')\n",
        "\n",
        "cnn_base.trainable = False"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjcnd1DxBLvG"
      },
      "source": [
        "\n",
        "pretrainedCNN_model = Sequential([\n",
        "                                     cnn_base,\n",
        "                                  layers.Flatten(),\n",
        "                                  layers.Dense(37, activation = 'softmax')  ,  \n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GOlssVeBRGD"
      },
      "source": [
        "pretrainedCNN_model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\"]\n",
        "              )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMAS9uQvCWbO"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/temp/checkpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor='accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtbtSmC2Cau3",
        "outputId": "4212c2c0-f82a-4732-979a-0bcc58f16c18"
      },
      "source": [
        "History = pretrainedCNN_model.fit(X_train, epochs=25,verbose=1,\n",
        "                                  callbacks=[model_checkpoint_callback])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "185/185 [==============================] - 170s 730ms/step - loss: 7.4917 - accuracy: 0.7097\n",
            "Epoch 2/25\n",
            "185/185 [==============================] - 136s 733ms/step - loss: 6.1442 - accuracy: 0.8163\n",
            "Epoch 3/25\n",
            "185/185 [==============================] - 136s 732ms/step - loss: 5.7011 - accuracy: 0.8484\n",
            "Epoch 4/25\n",
            "185/185 [==============================] - 136s 732ms/step - loss: 5.0008 - accuracy: 0.8696\n",
            "Epoch 5/25\n",
            "185/185 [==============================] - 135s 731ms/step - loss: 6.0919 - accuracy: 0.8615\n",
            "Epoch 6/25\n",
            "185/185 [==============================] - 135s 729ms/step - loss: 4.8086 - accuracy: 0.8839\n",
            "Epoch 7/25\n",
            "185/185 [==============================] - 135s 729ms/step - loss: 4.5548 - accuracy: 0.8924\n",
            "Epoch 8/25\n",
            "185/185 [==============================] - 135s 728ms/step - loss: 4.6745 - accuracy: 0.8959\n",
            "Epoch 9/25\n",
            "185/185 [==============================] - 135s 727ms/step - loss: 4.6507 - accuracy: 0.8958\n",
            "Epoch 10/25\n",
            "185/185 [==============================] - 136s 734ms/step - loss: 3.6230 - accuracy: 0.9182\n",
            "Epoch 11/25\n",
            "185/185 [==============================] - 137s 738ms/step - loss: 4.2766 - accuracy: 0.9122\n",
            "Epoch 12/25\n",
            "185/185 [==============================] - 137s 739ms/step - loss: 3.3110 - accuracy: 0.9256\n",
            "Epoch 13/25\n",
            "185/185 [==============================] - 135s 730ms/step - loss: 4.7189 - accuracy: 0.9148\n",
            "Epoch 14/25\n",
            "185/185 [==============================] - 135s 729ms/step - loss: 4.5014 - accuracy: 0.9134\n",
            "Epoch 15/25\n",
            "185/185 [==============================] - 136s 736ms/step - loss: 3.6932 - accuracy: 0.9236\n",
            "Epoch 16/25\n",
            "185/185 [==============================] - 136s 737ms/step - loss: 3.2812 - accuracy: 0.9316\n",
            "Epoch 17/25\n",
            "185/185 [==============================] - 137s 739ms/step - loss: 3.8190 - accuracy: 0.9304\n",
            "Epoch 18/25\n",
            "185/185 [==============================] - 137s 738ms/step - loss: 3.7568 - accuracy: 0.9312\n",
            "Epoch 19/25\n",
            "185/185 [==============================] - 137s 742ms/step - loss: 3.9902 - accuracy: 0.9295\n",
            "Epoch 20/25\n",
            "185/185 [==============================] - 136s 735ms/step - loss: 3.8811 - accuracy: 0.9295\n",
            "Epoch 21/25\n",
            "185/185 [==============================] - 136s 732ms/step - loss: 3.5243 - accuracy: 0.9328\n",
            "Epoch 22/25\n",
            "185/185 [==============================] - 137s 740ms/step - loss: 3.6173 - accuracy: 0.9358\n",
            "Epoch 23/25\n",
            "185/185 [==============================] - 137s 740ms/step - loss: 3.6003 - accuracy: 0.9368\n",
            "Epoch 24/25\n",
            "185/185 [==============================] - 140s 755ms/step - loss: 3.5463 - accuracy: 0.9389\n",
            "Epoch 25/25\n",
            "185/185 [==============================] - 137s 743ms/step - loss: 3.6109 - accuracy: 0.9407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGRq7igLapco"
      },
      "source": [
        "from glob import glob"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMfGYsATPhhJ"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "fname, test = [], []\n",
        "test_path = \"/content/TEST\"\n",
        "for infile in glob(test_path + \"/*.jpg\"):\n",
        "  img = Image.open(infile)\n",
        "  img = img.resize((300, 300))\n",
        "  fname.append(infile.split('/')[-1])\n",
        "  img_arr = np.asarray(img)\n",
        "  test.append(img_arr.reshape(300, 300, 3))\n",
        "\n",
        "test_len = len(test)\n",
        "test = np.array(test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwbUgSVLbaOr",
        "outputId": "3d2b0b0a-83d8-41ff-ddf9-e8dda5d251df"
      },
      "source": [
        "test_len"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ozo-nK5QW5F"
      },
      "source": [
        "dense = 0\n",
        "if dense == 1:\n",
        "    test = test.reshape(test_len, 3072)\n",
        "    \n",
        "test = test / 255.\n",
        "    \n",
        "y_test_pred = np.argmax(pretrainedCNN_model.predict(test), axis=1).tolist()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-m0Kd2CTYMT"
      },
      "source": [
        "labels = (X_train.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in y_test_pred]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I1Ch52NQZNr"
      },
      "source": [
        "submit = pd.DataFrame({'Filename': fname, 'Class': predictions})\n",
        "submit.to_csv('output2.csv', index=False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brhiZqr9RMoq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}